{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Machine Learning with K Nearest Neighbors",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "In this project, we'll use the KNN algorithm to classify instances from a fake dataset into one or the other target class.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline",
      "metadata": {
        "trusted": true
      },
      "execution_count": 3,
      "outputs": [
        {
          "ename": "<class 'ModuleNotFoundError'>",
          "evalue": "No module named 'seaborn'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      5\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatplotlib\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minline\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
          ],
          "output_type": "error"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "## Data",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df = pd.read_csv('../data/KNN_Project_Data.csv')",
      "metadata": {
        "trusted": true
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "df.head()",
      "metadata": {
        "trusted": true
      },
      "execution_count": 6,
      "outputs": [
        {
          "execution_count": 6,
          "output_type": "execute_result",
          "data": {
            "text/plain": "          XVPM         GWYH         TRAT        TLLZ         IGGA  \\\n0  1636.670614   817.988525  2565.995189  358.347163   550.417491   \n1  1013.402760   577.587332  2644.141273  280.428203  1161.873391   \n2  1300.035501   820.518697  2025.854469  525.562292   922.206261   \n3  1059.347542  1066.866418   612.000041  480.827789   419.467495   \n4  1018.340526  1313.679056   950.622661  724.742174   843.065903   \n\n          HYKR         EDFS        GUUB         MGJM         JHZC  \\\n0  1618.870897  2147.641254  330.727893  1494.878631   845.136088   \n1  2084.107872   853.404981  447.157619  1193.032521   861.081809   \n2  2552.355407   818.676686  845.491492  1968.367513  1647.186291   \n3   685.666983   852.867810  341.664784  1154.391368  1450.935357   \n4  1370.554164   905.469453  658.118202   539.459350  1899.850792   \n\n   TARGET CLASS  \n0             0  \n1             1  \n2             1  \n3             0  \n4             0  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>XVPM</th>\n      <th>GWYH</th>\n      <th>TRAT</th>\n      <th>TLLZ</th>\n      <th>IGGA</th>\n      <th>HYKR</th>\n      <th>EDFS</th>\n      <th>GUUB</th>\n      <th>MGJM</th>\n      <th>JHZC</th>\n      <th>TARGET CLASS</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1636.670614</td>\n      <td>817.988525</td>\n      <td>2565.995189</td>\n      <td>358.347163</td>\n      <td>550.417491</td>\n      <td>1618.870897</td>\n      <td>2147.641254</td>\n      <td>330.727893</td>\n      <td>1494.878631</td>\n      <td>845.136088</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1013.402760</td>\n      <td>577.587332</td>\n      <td>2644.141273</td>\n      <td>280.428203</td>\n      <td>1161.873391</td>\n      <td>2084.107872</td>\n      <td>853.404981</td>\n      <td>447.157619</td>\n      <td>1193.032521</td>\n      <td>861.081809</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1300.035501</td>\n      <td>820.518697</td>\n      <td>2025.854469</td>\n      <td>525.562292</td>\n      <td>922.206261</td>\n      <td>2552.355407</td>\n      <td>818.676686</td>\n      <td>845.491492</td>\n      <td>1968.367513</td>\n      <td>1647.186291</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1059.347542</td>\n      <td>1066.866418</td>\n      <td>612.000041</td>\n      <td>480.827789</td>\n      <td>419.467495</td>\n      <td>685.666983</td>\n      <td>852.867810</td>\n      <td>341.664784</td>\n      <td>1154.391368</td>\n      <td>1450.935357</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1018.340526</td>\n      <td>1313.679056</td>\n      <td>950.622661</td>\n      <td>724.742174</td>\n      <td>843.065903</td>\n      <td>1370.554164</td>\n      <td>905.469453</td>\n      <td>658.118202</td>\n      <td>539.459350</td>\n      <td>1899.850792</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "## Standardizing the Variables\nBecause of the type of data we're dealing with, it's important to standardize the variables before training our model. Skewed distribution of variables makes it harder for our model to deal with it.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from sklearn.preprocessing import StandardScaler",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "scaler = StandardScaler()",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "df.columns",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Of course, we don't need to scale the target class, so we'll ignore that during scaler fitting.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "scaler.fit(df.drop('TARGET CLASS',axis=1))",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Now we'll use the .transform() method to transform the features to a scaled version.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "scaled_feats = scaler.transform(df.drop('TARGET CLASS',axis=1))",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "#Converting the scaled features to a dataframe\nscaled_df = pd.DataFrame(scaled_feats)\nscaled_df.columns =['XVPM', 'GWYH', 'TRAT', 'TLLZ', 'IGGA', 'HYKR', 'EDFS', 'GUUB', 'MGJM',\n       'JHZC']",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "scaled_df.head()",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## Model Building",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Begin with splitting the data into training and test sets\nfrom sklearn.model_selection import train_test_split",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "X = scaled_df\ny = df['TARGET CLASS']",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Fitting our model.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from sklearn.neighbors import KNeighborsClassifier",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "knn = KNeighborsClassifier(n_neighbors=1)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "knn.fit(X_train,y_train)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## Predictions and Evaluations",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "predictions = knn.predict(X_test)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "from sklearn.metrics import classification_report,confusion_matrix",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "print(confusion_matrix(y_test,predictions))",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "print(classification_report(y_test,predictions))",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## Choosing a K Value",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "A major part of building a ML model with KNN, is choosing a K value to improve the performance of our model. Let's go ahead and use the elbow method to do that.\n\nWe will create a loop that trains various KNN models with different k values, then keep track of the error_rate for each of these models with a list.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "error_rate =[]\nfor i in range(1,50):\n    knn = KNeighborsClassifier(n_neighbors=i)\n    knn.fit(X_train,y_train)\n    predictions = knn.predict(X_test)\n    error_rate.append(np.mean(predictions != y_test))",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Now, to make it easier to see what values of K had lower error rates, we'll create a plot using the information from our for loop.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "plt.figure(figsize=(10,6))\nplt.plot(range(1,50),error_rate,color='blue', linestyle='dashed', marker='o',\n         markerfacecolor='red', markersize=10)\nplt.title('Error Rate vs. K Value')\nplt.xlabel('K')\nplt.ylabel('Error Rate')",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Looking at the plot,31 seems to be reasonable value for K. So let's retrain the model using that.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Retrain with new K Value",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "knn = KNeighborsClassifier(n_neighbors=31)\nknn.fit(X_train,y_train)\npredictions = knn.predict(X_test)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "print(confusion_matrix(y_test,predictions))\nprint(classification_report(y_test,predictions))",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Hence our model performs better!\n\nThis concludes this project.",
      "metadata": {}
    }
  ]
}